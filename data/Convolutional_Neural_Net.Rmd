---
title: "Pneumonia"
author: "Graham Chickering"
date: "11/13/2020"
output: pdf_document
---

```{r, message=FALSE}
library(tensorflow)
# library(tfdatasets)
library(keras)
#library(cloudml)
# library(tidyverse)
# library(sparklyr)
# library(ggplot2)
# library(readr) 
library(tictoc)
```


```{r}
chest_list <- c("NORMAL","PNEUMONIA")
output_n<-length(chest_list)

img_width <- 20
img_height <- 20
target_size <- c(img_width, img_height)

# RGB = 3 channels
channels <- 3

batch_size<-10

# path to image folders
train_image_files_path<- file.path("/Users/grahamchickering/Downloads/chest_xray/val")
#train_image_files_path <- file.path("/Users/grahamchickering/Downloads/chest_xray/train")
#val_image_files_path <- file.path("/Users/grahamchickering/Downloads/chest_xray/val")
#test_image_files_path<-file.path("/Users/grahamchickering/Downloads/chest_xray/test")
```

```{r}
train_data_gen = image_data_generator(
  rescale = 1/255,
  validation_split=0.2
)

# val_data_gen <- image_data_generator(
#   rescale = 1/255
#   )
# 
# test_data_gen<-image_data_generator(
#   rescale = 1/255
#   )  

```

```{r}
train_image_array_gen <- flow_images_from_directory(train_image_files_path, 
                                          train_data_gen,
                                          subset = 'training',
                                          target_size = target_size,
                                          #color_mode="grayscale",
                                          class_mode = "binary",
                                          classes = chest_list,
                                          shuffle=TRUE,
                                          batch_size=batch_size,
                                          seed = 27)

val_image_array_gen <- flow_images_from_directory(train_image_files_path, 
                                          train_data_gen,
                                          subset = 'validation',
                                          #color_mode="grayscale",
                                          target_size = target_size,
                                          class_mode = "binary",
                                          classes = chest_list,
                                          shuffle=TRUE,
                                          batch_size=batch_size,
                                          seed = 27)
# test_image_array_gen <- flow_images_from_directory(test_image_files_path, 
#                                           test_data_gen,
#                                           target_size = target_size,
#                                           subset='testing',
#                                           class_mode = "categorical",
#                                           classes = chest_list,
#                                           batch_size=batch_size,
#                                           seed = 27)
```

```{r}
table(factor(train_image_array_gen$classes))
table(factor(val_image_array_gen$classes))
```

```{r}
cat("\nClass label vs index mapping:\n")
train_image_array_gen$class_indices
```

```{r}
chest_classes_indices <- train_image_array_gen$class_indices
save(chest_classes_indices, file ="chest_indices.Rdata")
```


```{r}
# number of training samples
train_samples <- train_image_array_gen$n
# number of validation samples
valid_samples <- val_image_array_gen$n

# define batch size and number of epochs
batch_size <- 10
epochs <- 2
```

```{r}
model <- keras_model_sequential()

# add layers
model %>%
  layer_conv_2d(filter = 32, kernel_size = c(3,3), padding = "same", input_shape = c(img_width, img_height, channels)) %>%
  layer_activation("relu") %>%
  
  # Second hidden layer
  layer_conv_2d(filter = 16, kernel_size = c(3,3), padding = "same") %>%
  layer_activation_leaky_relu(0.5) %>%
  layer_batch_normalization() %>%

  # Use max pooling
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_dropout(0.25) %>%
  
  # Flatten max filtered output into feature vector 
  # and feed into dense layer
  layer_flatten() %>%
  layer_dense(100) %>%
  layer_activation("relu") %>%
  layer_dropout(0.5) %>%

  # Outputs from dense layer are projected onto output layer
  layer_dense(output_n) %>% 
  layer_activation("softmax")




# model <- keras_model_sequential() %>% 
#   layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu", 
#                 input_shape = c(20,20,1)) #%>% 
  # layer_max_pooling_2d(pool_size = c(2,2)) %>% 
  # layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>% 
  # layer_max_pooling_2d(pool_size = c(2,2)) %>% 
  # layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu")

```

```{r}
# model %>%
#   layer_flatten() %>%
#   layer_dense(units = 64, activation = "relu") %>%
# layer_dense(units = 10, activation = "softmax")

model %>% compile(
  optimizer = "adam",
  loss = "sparse_categorical_crossentropy",
  metrics = "accuracy"
)
summary(model)
```


```{r}
hist <- model %>% fit_generator(
  # training data
  train_image_array_gen,
  
  # epochs
  steps_per_epoch = as.integer(train_samples / batch_size), 
  epochs = epochs, 
  
  # validation data
  # validation_data = valid_image_array_gen,
  # validation_steps = as.integer(valid_samples / batch_size)
)
```

```{r}
sessionInfo()
```

